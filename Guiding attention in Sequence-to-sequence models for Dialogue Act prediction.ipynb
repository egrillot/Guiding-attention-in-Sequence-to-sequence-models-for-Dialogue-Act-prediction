{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Guiding attention in Sequence-to-sequence models for Dialogue Act prediction.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyM0PCMvuKqg6Lbmq0XKZwan"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"mtOlXAz6oWks"},"source":["The paper proposes a solution to dialog acts classification (DA) by enriching the work done in seq2seq problems, especially for Neural Machine Translation (NMT) problems. Indeed, we will see later on that we can observe some similarities in the modelling of the two problems. However, these two problems remain different on certain points which we will expose. The proposed solutions are based on answers to overcome these differences.\n","\n","Modelling :      \n","\n","\n","\n","1.   A dialogue $i$ will be modelled as follows for DA classifications:\n","\\begin{equation*}\n","C_i = (u^{(i)}_1, u^{(i)}_2, ..., u^{(i)}_{|C_i|})\n","\\end{equation*}\n","Where refers to a sentence in the dialogue. Note that the two protagonists do not necessarily speak regularly to each other (speaker 1 may say 5 sentences in a row while speaker 2 responds with a single sentence). A conversation is associated with a set of tags for each sentence :    \n","\\begin{equation*}\n","Y_i = (y^{(i)}_1, y^{(i)}_2, ..., y^{(i)}_{|C_i|})\n","\\end{equation*} \n","And finally we introduce :\n","\\begin{equation*}\n","C = (C_1, C_2, ..., C_{|C|})\\\\\n","Y = (Y_1, Y_2, ..., Y_{|C|})\n","\\end{equation*}\n","\n","2.   Now we focus on the modelling of the NMT problem, we define a sequence as follows :    \n","\\begin{equation*}\n","X^{l_1} = (x_1^{l_1}, x_2^{l_1}, ..., x_{|X^{l_1}|}^{l_1})\n","\\end{equation*}\n","Where $l_1$ is a language and each $x_i^{l_1}$ is a word composing the sentence and the goal is to predict the sequence below in an other language $l_2$ :\n","\\begin{equation*}\n","X^{l_2} = (x_1^{l_2}, x_2^{l_2}, ..., x_{|X^{l_2}|}^{l_2})\n","\\end{equation*}\n","\n","Similarities :    \n","\n","\n","1.   We can first constate that the goal is quite the same. Indeed, we need to maximise both following likelihood :  \n","\\begin{equation*}\n","P(X^{l_2} \\mid X^{l_1}) \\mbox{ and } P(Y_i \\mid C_i)\n","\\end{equation*}  \n","2.   For the two tasks, there are strong dependencies between units composing both the input and output sequences.\n","\n","Differencies :\n","\n","\n","1.   The input dimension in the case of DA classification is widely higher than the input dimension for NMT. Indeed, in the case of NMT, we have a sequence of words while in the DA case, we have a sequence of sequence of words ! Next, we will see in the code that with only 30 conversations, we have a space of dimension $1226*25*20*300$. \n","2.   The output length can be widely different between the input and output in the DA case in opposite with the NMT case. Indeed, languages like french and english doesn't provide such a different length for sentences which have same meanings while in the DA case the input size is around $25*20*300$ and in our case we have 78 tags which involves an output space of $25*78$\n","3.   And it is straightforward to notice with the second point that in opposite in the NMT case, we will have a problem of alignements between the $y_i$ and the $x_i$ which compose an utterance of the speech.\n","\n","\n","The main ideas will be to build encoders to reduce the large input space, to build decoders with guided attention methods to aligne the input and the outputs and finally exploit the beam search as the loss to not be bounded because of the vocabulary size (the loss isn't implemented here :( ) :     \n","\n","\\begin{equation*}\n","s(\\hat{y}^k, u_i) = \\frac{log P(\\hat{y}^k \\mid u_i)}{lp(\\hat{y}^k)}\n","\\end{equation*}\n","\n","Where $lp(x) = \\frac{(5 + |x|)^{\\alpha}}{(5+1)^{\\alpha}}$. \n","\n","In this notebook, we focus on the SwDA data and propose an implementation of each encoders and decoders proposed in the paper with an utils package to execute the benchmark done in the paper.\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ShQqVIkrCV-W"},"source":["#Data preprocessing"]},{"cell_type":"code","metadata":{"id":"WSHwC0jy7iDD"},"source":["!pip install gluonnlp\n","!pip install mxnet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"14K_da5iE_hb","executionInfo":{"status":"ok","timestamp":1637092682914,"user_tz":-60,"elapsed":737,"user":{"displayName":"Emilien Grillot","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13312381761603409646"}},"outputId":"a3344e4f-aa6e-4b89-fd45-5c1c420298b5"},"source":["import os\n","import pickle as pkl\n","import pandas as pd\n","import numpy as np\n","import gluonnlp as nlp\n","from sklearn.model_selection import train_test_split\n","from nltk import word_tokenize\n","import nltk\n","nltk.download('punkt')\n","\n","class SwDA:\n","\n","  def __init__(self, path='swda/', number_conversations=30):\n","\n","    self.C = [] #conversations\n","    self.Y = [] #list of list of tags\n","    self.Callers = [] #list of list of callers\n","    self.tags = set()\n","\n","    count = 0\n","    for path_conv in os.listdir(path):\n","      p = '/'.join((path, path_conv))\n","      if os.path.isdir(p):\n","        for csv in os.listdir(p):\n","          if count < number_conversations:\n","            if 'utt.csv' in csv:\n","              pp = '/'.join((path, path_conv, csv))\n","              df = pd.read_csv(pp)[['act_tag', 'caller', 'text']]\n","              tags = pd.unique(df['act_tag'])\n","              for tag in tags:\n","                self.tags.add(tag)\n","              self.Y.append(df['act_tag'].values)\n","              self.C.append(df['text'].values)\n","              self.Callers.append(df['caller'].values)\n","          count += 1\n","    \n","  def serialize_conversations(self, T=5**2):\n","    #serialize the raw data with a window of length T and clean the utterances \n","\n","    self.C_serialized = [] \n","    self.Y_serialized = []\n","    self.Callers_serialized = []\n","    self.words = set()\n","\n","    for i in range(len(self.C)):\n","      conv = []\n","      tags = []\n","      callers = []\n","\n","\n","      for t in range(T, len(self.C[i])):\n","        seq = self.C[i][t - T: t]\n","        seq_clean = []\n","        for utt in seq:\n","          words_utt = word_tokenize(utt)[-1]\n","          seq_clean.append(words_utt)\n","          for word in words_utt:\n","            self.words.add(word)\n","        conv.append(seq_clean)\n","        callers.append(self.Callers[i][t - T: t])\n","        tags.append(self.Y[i][t - T: t])\n","\n","      self.C_serialized += conv\n","      self.Y_serialized += tags\n","      self.Callers_serialized += callers\n","      \n","    self.C_serialized = np.asarray(self.C_serialized, dtype=object)\n","    self.Y_serialized = np.asarray(self.Y_serialized, dtype=object)\n","    self.Callers_serialized = np.asarray(self.Callers_serialized, dtype=object)\n","  \n","  def embedding_pad(self, T=5**2, max_length=20):\n","    #pad or make a troncature to have max_length words in each sequence\n","    #embedding with the fasttext embeddings layer\n","    # tab : array (number_sequence, T, max_length, 300)\n","\n","    #set fasttext\n","    counter = nlp.data.count_tokens([word for word in self.words])\n","    self.vocab = nlp.Vocab(counter)\n","    fasttext_simple = nlp.embedding.create('fasttext', source='wiki.simple')\n","    self.vocab.set_embedding(fasttext_simple)\n","\n","    tab = np.zeros((self.C_serialized.shape[0], T, max_length, 300))\n","    for i in range(self.C_serialized.shape[0]):\n","      for j in range(T):\n","        for k in range(len(self.C_serialized[i][j])):\n","          tab[i, j, k, :] = self.vocab.embedding[self.C_serialized[i][j][k]].asnumpy()\n","        tab[i, j, k+1:, :] = self.vocab.embedding['<pad>'].asnumpy()\n","    \n","    self.C_serialized = tab\n","  \n","  def one_hot_tags(self, T=5**2):\n","    #one hot encoding of tags\n","    \n","    tab = np.zeros((self.Y_serialized.shape[0], T, len(self.tags)))\n","    self.tags_dict = dict((tag, i) for (i, tag) in enumerate(self.tags))\n","\n","    for i in range(self.Y_serialized.shape[0]):\n","      for j in range(T):\n","        tab[i, j, self.tags_dict[self.Y_serialized[i][j]]] = 1.0\n","    self.Y_serialized = tab\n","\n","  def callers_process(self):\n","    #code by 1 and 0 callers 1 and B \n","\n","    self.Callers_serialized = np.where(self.Callers_serialized == 'A', 1.0, 0.0)\n","\n","  def preprocess(self, T=5**2, max_length=20):\n","    self.serialize_conversations(T)\n","    self.embedding_pad(T, max_length)\n","    self.one_hot_tags(T)\n","    self.callers_process()\n","\n","    #shuffle and split\n","\n","    self.callers_train, self.callers_test, self.conv_train, self.conv_test, self.y_train, self.y_test = train_test_split(self.Callers_serialized, \n","                                                                                                                         self.C_serialized, self.Y_serialized, test_size=.5, shuffle=True)\n","  \n","  def get_raw_data(self):\n","    #return the raw data\n","\n","    return self.Callers, self.C, self.Y\n","  \n","  def get_data(self):\n","    #return serialized utterances : callers for each utterance, utterances, tags\n","\n","    return self.callers_train, self.callers_test, self.conv_train, self.conv_test, self.y_train, self.y_test\n","  \n","  def save(self, path):\n","    with open(path, 'wb') as f:\n","      pkl.dump((self.callers_train, self.callers_test, self.conv_train, self.conv_test, self.y_train, self.y_test), f, protocol=4)\n","    f.close()\n","  \n","  def load(self, path):\n","    with open(path, 'rb') as f:\n","      self.callers_train, self.callers_test, self.conv_train, self.conv_test, self.y_train, self.y_test = pkl.load(f)\n","    f.close()\n","  "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","metadata":{"id":"lclq_PjwLCrQ"},"source":["#preprocess data\n","\n","dataset = SwDA()\n","dataset.preprocess()\n","dataset.save('data.pkl')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JIyeC148NUVV"},"source":["#or if it's already done...\n","\n","dataset = SwDA()\n","dataset.load('data.pkl')\n","callers_train, callers_test, conv_train, conv_test, tags_train, tags_test = dataset.get_data()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_oPQXS-_q_Oa","executionInfo":{"status":"ok","timestamp":1637081697060,"user_tz":-60,"elapsed":225,"user":{"displayName":"Emilien Grillot","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13312381761603409646"}},"outputId":"d7713b47-6576-4e89-b229-3247ccef1f97"},"source":["len(dataset.tags)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["78"]},"metadata":{},"execution_count":220}]},{"cell_type":"markdown","metadata":{"id":"_siPwS7qLXSG"},"source":["#Encoders"]},{"cell_type":"code","metadata":{"id":"XoGVX9TnLafq"},"source":["import keras\n","import tensorflow as tf\n","from keras import Model\n","from keras.layers import Bidirectional, GRU, Lambda, Concatenate, Reshape\n","from tensorflow.keras.backend import squeeze, repeat_elements\n","from keras.regularizers import l2\n","\n","#Vanilla RNN encoder\n","\n","class VGRUe(Model):\n","\n","  def __init__(self):\n","    super(VGRUe, self).__init__()\n","    \n","    self.mean_layer = Lambda( lambda x: tf.math.reduce_mean(x, axis=3))\n","    self.concatenate = Concatenate(axis=1)\n","    self.biGRU_1 = Bidirectional(GRU(128, return_sequences=True, dropout=0.2, kernel_regularizer=l2(1e-5)))\n","    self.biGRU_2 = Bidirectional(GRU(64, return_sequences=True, return_state=True, dropout=0.2, kernel_regularizer=l2(1e-5)))\n","\n","  def call(self, x): # x is a list of two elements: Callers and seq of Utterances\n","\n","    x = x[1]\n","    embedding_means = self.mean_layer(x)\n","    seq = self.biGRU_1(embedding_means)\n","    seq, state_h, state_c = self.biGRU_2(seq)\n","\n","    return seq, self.concatenate([state_h, state_c])\n","\n","\n","#Hierarchical encoders\n","\n","class HGRU(Model):\n","\n","  def __init__(self):\n","    super(HGRU, self).__init__()\n","\n","    self.word_seqs = Lambda( lambda x: tf.split(x, [1 for i in range(5**2)], axis=1))\n","    self.concatenate = Concatenate(axis=1)\n","    self.reshape = Reshape((1, 256))\n","\n","    self.biGRU_words = Bidirectional(GRU(128, return_sequences=False, return_state=False, dropout=0.2, kernel_regularizer=l2(1e-5)))\n","    self.biGRU_utt = Bidirectional(GRU(64, return_sequences=True, return_state=True, dropout=0.2, kernel_regularizer=l2(1e-5)))\n","  \n","  def call(self, x):\n","\n","    x = x[1]\n","    utts = self.word_seqs(x)\n","    words_dependencies = []\n","    for utt in utts:\n","      h = self.biGRU_words(squeeze(utt, axis=1))\n","      words_dependencies.append(self.reshape(h))\n","    words_dependencies = self.concatenate(words_dependencies)\n","    seq, state_h, state_c = self.biGRU_utt(words_dependencies)\n","\n","    return seq, self.concatenate([state_h, state_c])\n","\n","\n","#Persona hierarchical encoders\n","\n","class PersoHGRU(Model):\n","\n","  def __init__(self):\n","    super(PersoHGRU, self).__init__()\n","\n","    self.word_seqs = Lambda( lambda x: tf.split(x, [1 for i in range(5**2)], axis=1))\n","    self.speaker_differentes_right = Lambda( lambda x: tf.math.abs(tf.subtract(x, tf.roll(x, shift=1, axis=1))))\n","    self.speaker_differentes_left = Lambda( lambda x: tf.math.abs(tf.subtract(x, tf.roll(x, shift=24, axis=1))))\n","    self.concatenate = Concatenate(axis=1)\n","    self.reshape = Reshape((1, 256))\n","\n","    self.biGRU_words = Bidirectional(GRU(128, return_sequences=False, return_state=False, dropout=0.2, kernel_regularizer=l2(1e-5)))\n","    self.GRU_persona_left = GRU(128, return_sequences=False, return_state=False, dropout=0.2, kernel_regularizer=l2(1e-5))\n","    self.GRU_persona_right = GRU(128, return_sequences=False, return_state=False, dropout=0.2, kernel_regularizer=l2(1e-5))\n","    self.biGRU_utt = Bidirectional(GRU(64, return_sequences=True, return_state=True, dropout=0.2, kernel_regularizer=l2(1e-5)))\n","  \n","  def call(self, x):\n","\n","    c = x[0]\n","    c_right = repeat_elements(Reshape((25, 1))(self.speaker_differentes_right(c)), rep=256, axis=-1)\n","    c_left = repeat_elements(Reshape((25, 1))(self.speaker_differentes_left(c)), rep=256, axis=-1)\n","    u = x[1]\n","    utts = self.word_seqs(u)\n","    words_dependencies = []\n","    for utt in utts:\n","      h = self.biGRU_words(squeeze(utt, axis=1))\n","      words_dependencies.append(self.reshape(h))\n","    words_dependencies = self.concatenate(words_dependencies)\n","    persona_left = c_left * words_dependencies\n","    persona_right = c_right * words_dependencies\n","    p_left = self.word_seqs(persona_left)\n","    p_right = self.word_seqs(persona_right)\n","    persona = []\n","    for t in range(5**2):\n","      l = self.GRU_persona_left(p_left[t])\n","      r = self.GRU_persona_right(p_right[t])\n","      persona.append(Reshape((1, 256))(self.concatenate([l, r])))\n","    persona = self.concatenate(persona)\n","    seq, state_h, state_c = self.biGRU_utt(persona)\n","\n","    return seq, self.concatenate([state_h, state_c])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WPiJ1H1Q7Wmg"},"source":["#Decoders"]},{"cell_type":"code","metadata":{"id":"l4o6fXuJ7YnP"},"source":["import keras\n","import tensorflow as tf\n","from keras import Model\n","from keras.layers import GRU, Dense, Concatenate, Reshape\n","from keras.regularizers import l2\n","from keras.activations import softmax\n","\n","\n","#Vanilla decoder\n","\n","class VGRUd(Model):\n","\n","  def __init__(self, encoder):\n","    super(VGRUd, self).__init__()\n","\n","    self.encoder = encoder #type Model\n","    self.gru_decoder = GRU(64, return_sequences=True, return_state=True, dropout=0.2, kernel_regularizer=l2(1e-5))\n","    self.dense_softmax = Dense(78, activation='softmax', kernel_regularizer=l2(1e-5)) #78 tags\n","    self.concatenate = Concatenate(axis=1)\n","\n","  def call(self, x):\n","\n","    seq, H = self.encoder(x)\n","    input = Reshape((1, 128))(x[1][:, 0, 0, :128])\n","    state = Reshape((64, ))(H)\n","    outputs = []\n","    for t in range(5**2):\n","      input, state = self.gru_decoder(input, initial_state=state)\n","      outputs.append(input)\n","    outputs = self.concatenate(outputs)\n","\n","    return self.dense_softmax(outputs)\n","\n","#Decoders with attention\n","\n","#Vanilla attention\n","\n","class VGRUatt(Model):\n","\n","  def __init__(self, encoder):\n","    super(VGRUatt, self).__init__()\n","  \n","    self.encoder = encoder \n","    self.seqs = Lambda( lambda x: tf.split(x, [1 for i in range(5**2)], axis=1))\n","    self.gru_decoder = GRU(128, return_sequences=True, return_state=True, dropout=0.2, kernel_regularizer=l2(1e-5))\n","    self.dense_softmax = Dense(78, activation='softmax', kernel_regularizer=l2(1e-5)) #78 tags\n","    self.concatenate = Concatenate(axis=1)\n","    self.dense_attention = Dense(128, activation=None, kernel_regularizer=l2(1e-5)) \n","  \n","  def call(self, x):\n","\n","    seq, H = self.encoder(x)\n","\n","    hs = self.seqs(seq)\n","    input = Reshape((1, 128))(x[1][:, 0, 0, :128])\n","    state = Reshape((128, ))(H)\n","    outputs = []\n","    for t in range(5**2):\n","      input, state = self.gru_decoder(input, initial_state=state)\n","      alphas = []\n","      for i in range(5**2):\n","        score = self.dense_attention(hs[i])\n","        alphas.append(tf.math.reduce_sum(tf.multiply(score, input), axis=2))\n","      alphas = self.concatenate(alphas)\n","      alphas = softmax(alphas, axis=-1)\n","      alphas = self.seqs(alphas)\n","      state = tf.multiply(Reshape((1, 1))(alphas[0]), hs[0])\n","      for i in range(1, 5**2):\n","        state += tf.multiply(Reshape((1, 1))(alphas[i]), hs[i])\n","      state = Reshape((128, ))(state)\n","      outputs.append(input)\n","    outputs = self.concatenate(outputs)\n","\n","    return self.dense_softmax(outputs)\n","\n","#Hard guided attention\n","\n","class VGRUhga(Model):\n","\n","  def __init__(self, encoder):\n","    super(VGRUhga, self).__init__()\n","\n","    self.encoder = encoder \n","    self.seqs = Lambda( lambda x: tf.split(x, [1 for i in range(5**2)], axis=1))\n","    self.gru_decoder = GRU(128, return_sequences=True, return_state=True, dropout=0.2, kernel_regularizer=l2(1e-5))\n","    self.dense_softmax = Dense(78, activation='softmax', kernel_regularizer=l2(1e-5)) #78 tags\n","    self.concatenate = Concatenate(axis=1)\n","\n","  def call(self, x):\n","\n","    seq, H = self.encoder(x)\n","\n","    hs = self.seqs(seq)\n","    input = Reshape((1, 128))(x[1][:, 0, 0, :128])\n","    state = Reshape((128, ))(H)\n","    input, state = self.gru_decoder(input, initial_state=state)\n","    outputs = [input]\n","    for t in range(1, 5**2):\n","      input, state = self.gru_decoder(input, initial_state=state)\n","      state = Reshape((128, ))(hs[t])\n","      outputs.append(input)\n","    outputs = self.concatenate(outputs)\n","\n","    return self.dense_softmax(outputs)\n","  \n","#Soft guided attention\n","\n","class VGRUsga(Model):\n","\n","  def __init__(self, encoder):\n","    super(VGRUsga, self).__init__()\n","  \n","    self.encoder = encoder \n","    self.seqs = Lambda( lambda x: tf.split(x, [1 for i in range(5**2)], axis=1))\n","    self.gru_decoder = GRU(128, return_sequences=True, return_state=True, dropout=0.2, kernel_regularizer=l2(1e-5))\n","    self.dense_softmax = Dense(78, activation='softmax', kernel_regularizer=l2(1e-5)) #78 tags\n","    self.concatenate = Concatenate(axis=1)\n","    self.dense_attention = Dense(128, activation=None, kernel_regularizer=l2(1e-5)) \n","  \n","  def call(self, x):\n","\n","    seq, H = self.encoder(x)\n","\n","    hs = self.seqs(seq)\n","    input = Reshape((1, 128))(x[1][:, 0, 0, :128])\n","    state = Reshape((128, ))(H)\n","    outputs = []\n","    for t in range(5**2):\n","      input, state = self.gru_decoder(input, initial_state=state)\n","      alphas = []\n","      for i in range(5**2):\n","        score = self.dense_attention(hs[i])\n","        a = tf.math.reduce_sum(tf.multiply(score, input), axis=2)\n","        if i == t:\n","          alphas.append(tf.add(1.0, a))\n","        else:\n","          alphas.append(a)\n","      alphas = self.concatenate(alphas)\n","      alphas = softmax(alphas, axis=-1)\n","      alphas = self.seqs(alphas)\n","      state = tf.multiply(Reshape((1, 1))(alphas[0]), hs[0])\n","      for i in range(1, 5**2):\n","        state += tf.multiply(Reshape((1, 1))(alphas[i]), hs[i])\n","      state = Reshape((128, ))(state)\n","      outputs.append(input)\n","    outputs = self.concatenate(outputs)\n","\n","    return self.dense_softmax(outputs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0jZjmg5c7Y7Y"},"source":["#Train and Test models"]},{"cell_type":"code","metadata":{"id":"etniqtGT7bCI"},"source":["#utils\n","\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import categorical_crossentropy\n","from tensorflow.keras.metrics import Accuracy\n","from keras.callbacks import LearningRateScheduler\n","\n","def scheduler(epoch, lr):\n","   if epoch < 20:\n","     return lr\n","   else:\n","     return lr * 0.5\n","\n","def compile_fit(model):\n","  model.compile(optimizer=Adam(learning_rate=0.01, clipnorm=5.), loss=categorical_crossentropy(), metrics=Accuracy())\n","  callbacks = LearningRateScheduler(scheduler)\n","  model.fit(x=[callers_train, conv_train], y=tags_train, epochs=500, validation_split=.2, callbacks=[callbacks], shuffle=True)\n","\n","def test(model):\n","  model.test(x=[callers_test, conv_test], y=tags_test)\n","\n","def benchmark():\n","  #find paper results\n","\n","  models = {'VGRUe-VGRUd': VGRUd(VGRUe()),\n","            'HGRU-VGRUd': VGRUd(HGRU()),\n","            'PersoHGRU-VGRUd': VGRUd(PersoHGRU()),\n","            'VGRUe-VGRUatt': VGRUatt(VGRUe()),\n","            'HGRU-VGRUatt': VGRUatt(HGRU()),\n","            'PersoHGRU-VGRUatt': VGRUatt(PersoHGRU()),\n","            'VGRUe-VGRUhga': VGRUhga(VGRUe()),\n","            'HGRU-VGRUhga': VGRUhga(HGRU()),\n","            'PersoHGRU-VGRUhga': VGRUhga(PersoHGRU()),\n","            'VGRUe-VGRUsga': VGRUsga(VGRUe()),\n","            'HGRU-VGRUsga': VGRUsga(HGRU()),\n","            'PersoHGRU-VGRUsga': VGRUsga(PersoHGRU()),\n","              }\n","\n","  for model in models:\n","    print('Training {} model ...'.format(model))\n","    compile_fit(models[model])\n","    print('Testing {} model ...'.format(model))\n","    test(models[model])\n","  "],"execution_count":null,"outputs":[]}]}